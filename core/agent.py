import sys
import subprocess
import tempfile
import os
import ast
import re
import json
import platform
from datetime import datetime
from PySide6.QtCore import QThread, Signal
from core.skill_manager import SkillManager

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class SecurityError(Exception):
    pass

def validate_code_safety(code, allowed_dir):
    """AST é™æ€åˆ†æä»£ç å®‰å…¨æ€§"""
    try:
        tree = ast.parse(code)
    except SyntaxError as e:
        raise SecurityError(f"Syntax Error: {e}")

    allowed_dir = os.path.abspath(allowed_dir).lower()

    for node in ast.walk(tree):
        if isinstance(node, ast.Constant) and isinstance(node.value, str):
            val = node.value
            if ".." in val:
                 raise SecurityError(f"Security Alert: Path traversal '..' detected in string: '{val}'")
            if os.path.isabs(val):
                abs_val = os.path.abspath(val).lower()
                if not abs_val.startswith(allowed_dir):
                     raise SecurityError(f"Security Alert: Unauthorized absolute path access: '{val}'")
    return True

class CodeWorker(QThread):
    """åå°æ‰§è¡Œ Python ä»£ç çš„çº¿ç¨‹"""
    output_signal = Signal(str)
    finished_signal = Signal()
    input_request_signal = Signal(str)

    def __init__(self, code, cwd):
        super().__init__()
        self.code = code
        self.cwd = cwd
        self.process = None
        self.is_stopped = False

    def provide_input(self, text):
        """Write user input to stdin"""
        if self.process and self.process.stdin:
            try:
                self.process.stdin.write(text + "\n")
                self.process.stdin.flush()
            except Exception as e:
                print(f"Error writing to stdin: {e}")

    def stop(self):
        self.is_stopped = True
        if self.process:
            try:
                self.process.terminate() # Try graceful termination
                self.output_signal.emit("System: Terminating process...")
            except:
                pass

    def run(self):
        temp_path = None
        try:
            # 1. Validation
            try:
                validate_code_safety(self.code, self.cwd)
            except SecurityError as e:
                self.output_signal.emit(f"âŒ {str(e)}")
                # We will let the finally block emit finished_signal
                return

            # Prepend input() override to capture user interaction
            input_override = """
import sys
import io

# Set stdout/stderr to utf-8 explicitly for Windows console
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def input(prompt=""):
    print(f"__REQUEST_INPUT__:{prompt}", flush=True)
    return sys.stdin.readline().strip()
"""
            full_code = input_override + "\n" + self.code

            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as f:
                f.write(full_code)
                temp_path = f.name

            # Determine python executable
            python_exe = sys.executable
            if getattr(sys, 'frozen', False):
                # If frozen (packaged), sys.executable is the exe itself.
                # We need to find the system python or bundled python to run the script.
                
                # Check for bundled python in 'python_env' subdirectory
                # For onedir: os.path.dirname(sys.executable)/python_env/python.exe
                # For onefile: sys._MEIPASS/python_env/python.exe
                
                base_dir = os.path.dirname(sys.executable)
                possible_paths = [
                    os.path.join(base_dir, "python_env", "python.exe"),
                    os.path.join(base_dir, "_internal", "python_env", "python.exe")
                ]
                
                if hasattr(sys, '_MEIPASS'):
                    possible_paths.insert(0, os.path.join(sys._MEIPASS, "python_env", "python.exe"))
                
                python_exe = "python" # Default fallback
                
                found_bundled = False
                for p in possible_paths:
                    if os.path.exists(p):
                        python_exe = p
                        found_bundled = True
                        break
                
                if not found_bundled:
                    # Try finding 'python' in PATH
                    import shutil
                    sys_python = shutil.which("python")
                    if sys_python:
                        python_exe = sys_python
                    else:
                        # Fallback: try standard install paths or warn user
                        self.output_signal.emit("âš ï¸ Warning: Bundled Python not found and System 'python' not found in PATH.")
                        # We stick to sys.executable but it likely won't work for scripts if onefile
                        python_exe = "python" 

            if self.is_stopped: return

            # Force environment variables for UTF-8 encoding
            env = os.environ.copy()
            env["PYTHONIOENCODING"] = "utf-8"

            self.output_signal.emit(f"Running with {python_exe} in: {self.cwd}...")
            self.process = subprocess.Popen(
                [python_exe, temp_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                stdin=subprocess.PIPE, # Enable stdin for input()
                text=True,
                cwd=self.cwd,
                encoding='utf-8', # å¼ºåˆ¶ UTF-8 é¿å…ä¸­æ–‡ä¹±ç 
                errors='replace',
                bufsize=0, # Unbuffered for real-time
                env=env # Apply environment variables
            )
            
            # Real-time output reading
            while True:
                if self.is_stopped:
                    self.process.kill()
                    self.output_signal.emit("âš ï¸ Process stopped by user.")
                    break
                
                output = self.process.stdout.readline()
                if output == '' and self.process.poll() is not None:
                    break
                if output:
                    output = output.strip()
                    if output.startswith("__REQUEST_INPUT__:"):
                        prompt = output.split(":", 1)[1]
                        self.input_request_signal.emit(prompt)
                    else:
                        self.output_signal.emit(output)
            
            if not self.is_stopped:
                stderr = self.process.stderr.read()
                if stderr:
                    self.output_signal.emit(f"Error Output:\n{stderr}")
            
        except Exception as e:
            self.output_signal.emit(f"Execution Error: {e}")
            # Also print to console for debugging
            import traceback
            traceback.print_exc()
            
        finally:
            # Clean up temp file
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except:
                    pass
            self.finished_signal.emit()

class LLMWorker(QThread):
    """åå°è°ƒç”¨ LLM API çš„çº¿ç¨‹ï¼Œæ”¯æŒ Tool Calls å’Œå¤šè½®æ€è€ƒ"""
    finished_signal = Signal(dict)
    step_signal = Signal(str) # ç”¨äºè¾“å‡ºä¸­é—´æ­¥éª¤æ—¥å¿—
    skill_used_signal = Signal(str) # Signal to report active skill usage

    def __init__(self, messages, config_manager, workspace_dir=None, parent_agent_id=None):
        super().__init__()
        self.messages = messages
        self.config_manager = config_manager
        self.api_key = config_manager.get("api_key")
        self.workspace_dir = workspace_dir
        self.parent_agent_id = parent_agent_id
        
        # Flags for control
        self.is_paused = False
        self.is_stopped = False
        
        # Initialize Skill Manager
        self.skill_manager = SkillManager(workspace_dir, config_manager)
        self.tools = self.skill_manager.get_tool_definitions()

    def pause(self):
        self.is_paused = True
        self.step_signal.emit("System: Paused.")

    def resume(self):
        self.is_paused = False
        self.step_signal.emit("System: Resumed.")

    def stop(self):
        self.is_stopped = True
        self.is_paused = False # Ensure loop breaks if paused
        self.step_signal.emit("System: Stopping...")

    def run(self):
        # Work on a copy of messages to handle multi-turn locally
        current_messages = self.messages.copy()
        
        # Construct System Context
        context_lines = [
            f"Current Workspace: {self.workspace_dir}",
            f"Operating System: {platform.system()} {platform.release()}",
            f"Python Version: {sys.version.split()[0]}",
            f"Current Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "Note: You are operating within the specified workspace. All file operations should be relative to this path unless explicitly absolute and allowed.",
            "Capability: You can create new skills/tools using 'create_new_skill'.",
            "Policy [SKILL CREATION]:",
            "1. ONLY create new skills for reusable *algorithmic* or *system operation* tasks (e.g., specific file processing, complex calculations, data transformation).",
            "2. DO NOT create skills for tasks that you can perform naturally as an LLM (e.g., text summarization, translation, creative writing, code explanation). Just output the result directly.",
            "3. When you encounter a task that requires a new reusable tool, define it as a skill.",
            "",
            "Policy [INTERACTION]: If you need to ask the user a question or get confirmation (e.g., for deleting files, clarification, or next steps), you MUST use the 'ask_user_confirmation' tool.",
            "DO NOT ask the question in the text response. The text response is for reasoning and final answers only. Use the tool to trigger a popup dialog."
        ]
        if self.parent_agent_id:
            context_lines.append(f"Note: You are a sub-agent (ID: {self.parent_agent_id}). Perform your assigned task efficiently.")

        system_prompt = "\n".join(context_lines)
        
        # Insert System Message
        current_messages.insert(0, {"role": "system", "content": system_prompt})
        
        full_reasoning = ""
        final_content = ""
        turn_count = 0
        
        last_tool_signature = None
        repetition_count = 0
        
        while True:
            # Check Control Flags
            while self.is_paused:
                if self.is_stopped: break
                self.msleep(100)
            if self.is_stopped: 
                final_content = "âš ï¸ Operation stopped by user."
                break

            turn_count += 1
            self.step_signal.emit(f"Turn {turn_count}: Requesting LLM...")

            if self.api_key and OPENAI_AVAILABLE:
                try:
                    client = OpenAI(api_key=self.api_key, base_url="https://api.deepseek.com")
                    response = client.chat.completions.create(
                        model="deepseek-reasoner", # or deepseek-chat with extra_body
                        messages=current_messages,
                        tools=self.tools,
                        # extra_body={"thinking": {"type": "enabled"}} # If using deepseek-chat
                    )
                    
                    msg = response.choices[0].message
                    content = msg.content or ""
                    tool_calls = msg.tool_calls
                    
                    # Extract reasoning
                    reasoning = getattr(msg, 'reasoning_content', "") or ""
                    if reasoning:
                        full_reasoning += f"\n[Step {turn_count}]: {reasoning}"
                        # Emit full reasoning with a special prefix so UI can handle it
                        self.step_signal.emit(f"Reasoning: {reasoning}")

                    # Append Assistant Message to History
                    current_messages.append(msg)
                    
                    if tool_calls:
                        # --- Loop Detection ---
                        try:
                            current_signature = json.dumps(
                                sorted([{"name": t.function.name, "args": json.loads(t.function.arguments)} for t in tool_calls], key=lambda x: x['name']),
                                sort_keys=True
                            )
                            if current_signature == last_tool_signature:
                                repetition_count += 1
                            else:
                                repetition_count = 0
                                last_tool_signature = current_signature
                                
                            if repetition_count >= 3: # Same toolset called 4 times in a row
                                self.step_signal.emit("System: ğŸ›‘ Loop detected (repeated tool calls). Stopping automatically.")
                                final_content = "âš ï¸ Operation stopped: Infinite loop detected (repeated tool calls)."
                                break
                        except Exception as e:
                            print(f"Loop detection error: {e}")
                        # ----------------------

                        self.step_signal.emit(f"Tool Calls Detected: {len(tool_calls)}")
                        for tool in tool_calls:
                            # Check Control Flags inside tool loop
                            while self.is_paused:
                                if self.is_stopped: break
                                self.msleep(100)
                            if self.is_stopped: break
                            
                            name = tool.function.name
                            args = json.loads(tool.function.arguments)
                            self.step_signal.emit(f"Executing Tool: {name}({args})")
                            
                            # Report Active Skill
                            skill_name = self.skill_manager.get_skill_of_tool(name)
                            if skill_name:
                                self.skill_used_signal.emit(skill_name)
                            
                            # Execute via Skill Manager
                            # Pass step_signal as context to allow tools to log
                            result = self.skill_manager.call_tool(name, args, context={"step_signal": self.step_signal, "config_manager": self.config_manager})
                            
                            current_messages.append({
                                "role": "tool",
                                "tool_call_id": tool.id,
                                "content": str(result) # Ensure content is string to avoid API errors
                            })
                            self.step_signal.emit(f"Tool Result: {result}")
                        # Loop continues to let LLM see tool results
                        continue
                    else:
                        # Final Answer
                        final_content = content
                        break
                        
                except Exception as e:
                    self.finished_signal.emit({"error": str(e)})
                    return
            else:
                # --- Mock Logic / Warning for Missing API Key ---
                import time
                time.sleep(1)
                
                reasoning = "æ£€æµ‹åˆ° API Key æœªé…ç½®æˆ– OpenAI åº“ä¸å¯ç”¨ã€‚æ— æ³•è¿æ¥åˆ° DeepSeek æ¨¡å‹ã€‚"
                full_reasoning += f"\n[System]: {reasoning}"
                self.step_signal.emit(f"System: {reasoning}")
                
                final_content = (
                    "âš ï¸ **æœªé…ç½® API Key**\n\n"
                    "è¯·ç‚¹å‡»å³ä¸Šè§’çš„ **âš™ï¸ è®¾ç½®** æŒ‰é’®é…ç½®æ‚¨çš„ DeepSeek API Keyã€‚\n"
                    "é…ç½®å®Œæˆåï¼Œæˆ‘å°†èƒ½å¤Ÿä¸ºæ‚¨æ‰§è¡Œå¤æ‚çš„æ–‡ä»¶æ“ä½œå’Œä»£ç ç”Ÿæˆä»»åŠ¡ã€‚"
                )
                
                break

        self.finished_signal.emit({
            "reasoning": full_reasoning.strip(),
            "content": final_content,
            "role": "assistant"
        })
